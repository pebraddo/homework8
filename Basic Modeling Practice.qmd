---
title: "Homework 8 Basic Modeling Practice"
author: "Powell Braddock, ST 558"
format: html
editor: visual
---

Variables of Interest:

• Date : day/month/year

• Rented Bike count - Count of bikes rented at each hour

• Hour - Hour of the day

• Temperature-Temperature in Celsius

• Humidity - %

• Windspeed - m/s

• Visibility - 10m

• Dew point temperature - Celsius

• Solar radiation - MJ/m2

• Rainfall - mm

• Snowfall - cm

• Seasons - Winter, Spring, Summer, Autumn

• Holiday - Holiday/No holiday

• Functional Day - NoFunc(Non Functional Hours), Fun(Functional hours)

## Reading in the Data

```{r}
library(tidyverse)

#originally got an error: what I think came from the degree symbol in one of the attributes.  the wild internet provided the locale = latin1 solution!
seoul_bike_data <- read_csv('https://www4.stat.ncsu.edu/~online/datasets/SeoulBikeData.csv', locale = locale(encoding = 'latin1'))
seoul_bike_data
```

## EDA

Checking the Data

You should have a narrative through what you are doing here! Don’t just put the steps with text verbatim. Practice writing! Steps you should definitely do:

1\. Check for missingness

```{r}
sum_na <- function(column){
  sum(is.na(column) + is.null(column) + is.nan(column))
}
na_counts <- seoul_bike_data |>
  summarize(across(everything(), sum_na))
na_counts
```

2\. Check the column types and the values within the columns to make sure they make sense (basic summary stats for numeric columns and check the unique values for the categorical variables).

```{r}
library(psych)
psych::describe(seoul_bike_data)
```

3\. Convert the Date column into an actual date (if need be). Recall the lubridate package.

```{r}
library(lubridate)
seoul_bike_date <-
  seoul_bike_data |> mutate(Date = dmy(Date))
```

4\. Turn the character variables (Seasons, Holiday, and Functioning Day) into factors.

```{r}
seoul_bike_data<-
seoul_bike_data |>
  mutate(Seasons = as.factor(Seasons),
         Holiday = as.factor(Holiday),
         `Functioning Day` = as.factor(`Functioning Day`)) |>
  rename('date'='Date',
         'rented_bike_count' = 'Rented Bike Count',
         'hour' = 'Hour',
         'celcius_temp' = 'Temperature(°C)',
         'percent_humidity'='Humidity(%)',
         'wind_speed'= 'Wind speed (m/s)',
         'visib'='Visibility (10m)',
         'dew_point_temp' = 'Dew point temperature(°C)',
         'solar_rad'='Solar Radiation (MJ/m2)',
         'rainfall' = 'Rainfall(mm)',
         'snowfall' = 'Snowfall (cm)',
         'seasons' = 'Seasons',
         'holiday' = 'Holiday',
         'function_day' = 'Functioning Day')
```

5\. Lastly, rename all the variables to have easy to use names (I use lower snake case but whatever you’d like is fine)

6\. Create summary statistics (especially related to the bike rental count). These should be done across your categorical variables as well. You should notice something about the Functioning Day variable. Subset the data appropriately based on that.

```{r}
seoul_bike_data |>
  group_by(function_day) |>
  summarize(across(rented_bike_count, .fns = list("mean" = mean, 
                                       "median" = median, 
                                       "var" = var, 
                                       "sd" = sd, 
                                       "IQR" = IQR), .names = "{.fn}_{.col}"))
```

```{r}
seoul_bike_data |>
  group_by(seasons, holiday) |>
  filter(function_day == 'Yes') |>
  summarize(across(rented_bike_count, .fns = list("mean" = mean, 
                                       "median" = median, 
                                       "var" = var, 
                                       "sd" = sd, 
                                       "IQR" = IQR), .names = "{.fn}_{.col}"))
```

7\. To simplify our analysis, we’ll summarize across the hours so that each day has one observation associated with it.

```{r}
seoul_bike_data |>
  group_by(date) |>
  filter(function_day == 'Yes') |>
  summarize(across(rented_bike_count, .fns = list("mean" = mean, 
                                       "median" = median), .names = "{.fn}_{.col}"))
```

```{r}
new_bike_data <- seoul_bike_data |>
  group_by(date, seasons, holiday) |>
  summarize(across(c(rented_bike_count,
                     rainfall,
                     snowfall), 
                   .fns=list('sum'=sum), 
                   .names = "{.fn}_{.col}"),
            across(c(celcius_temp, 
                     percent_humidity,
                     wind_speed,
                     visib,
                     dew_point_temp, 
                     solar_rad, 
                     rainfall,
                     snowfall), 
                   .fns = list("mean" = mean), 
                   .names = "{.fn}_{.col}")) |> 
  mutate(date = dmy(date))

new_bike_data
```

• (I’m using my new names here. Your names may not match and that’s ok!) Let’s group_by() the date, seasons, and holiday variables.

• Find the sum of the bike_count, rainfall, and snowfall variables

• Find the mean of all the weather related variables.

• This will be our new data that we’ll analyze!

8\. Recreate your basic summary stats and then create some plots to explore relationships. Report correlation between your numeric variables as well. Again, you should have a narrative throughout this!

```{r}
new_bike_data |>
  group_by(seasons, holiday)|>
  summarize(count=n()) |>
  pivot_wider(names_from = holiday, values_from = count)
```

```{r}
library(corrr)
psych::describe(new_bike_data)
num_vars <- new_bike_data |>
  select(sum_rented_bike_count, sum_rainfall, sum_snowfall, mean_celcius_temp, mean_percent_humidity, mean_wind_speed, mean_visib, mean_dew_point_temp, mean_solar_rad, mean_rainfall, mean_snowfall)
num_vars
```

```{r}
ggplot(new_bike_data, 
       aes(x=date, y=sum_rented_bike_count, color=holiday)) + 
  geom_point() + geom_smooth(method='lm') +
  scale_x_date(date_labels = "%B %d, %Y") +
  labs(title='Rented Bike Count Summed per Day in Seoul Scatterplot', x='Date',y='Rented Bike Count')
```

```{r}
ggplot(new_bike_data, 
       aes(x=mean_rainfall, y=sum_rented_bike_count, color=mean_visib)) + 
  geom_point() + 
  labs(title='Rented Bike Count Summed per Day Versus \nMean Rainfall and Mean Visibility in Seoul Scatterplot', x='Rainfall - mm',y='Rented Bike Count')
```

```{r}
ggplot(new_bike_data, 
       aes(x=mean_snowfall, y=sum_rented_bike_count, color=mean_wind_speed)) + 
  geom_point() + 
  labs(title='Rented Bike Count Summed per Day Versus \nMean Snowfall and Mean Wind Speed in Seoul Scatterplot', x='Rainfall - mm',y='Rented Bike Count')
```

```{r}
cor_matrix <- correlate(num_vars)
cor_matrix <- shave(cor_matrix)
rplot(cor_matrix, print_cor = TRUE) + 
  theme(axis.text.x = element_text(angle = 60, hjust = 1))
```

```{r}
ggplot(new_bike_data, 
       aes(x=mean_celcius_temp, y=sum_rented_bike_count, color=mean_solar_rad)) + 
  geom_point() + 
  labs(title='Rented Bike Count Summed per Day Versus \nMean Temperature and Mean Solar Radiation \nin Seoul Scatterplot', x='Temperature in Celcius',y='Rented Bike Count')
```

```{r}
ggplot(new_bike_data, 
       aes(x=mean_celcius_temp, y=sum_rented_bike_count, color=mean_dew_point_temp)) + 
  geom_point() + 
  labs(title='Rented Bike Count Summed per Day Versus \nMean Temperature and Mean Dew Point Temperature \nin Seoul Scatterplot', x='Temperature in Celcius',y='Rented Bike Count')
```

# Split the Data

• Use functions from tidymodels to split the data into a training and test set (75/25 split). Use the strata argument to stratify the split on the seasons variable.

```{r}
##library(tidymodels)
##seoul_data <- initial_split(new_bike_data, prop = 0.75)
##seoul_train <- training(seoul_data)
##seoul_test <- testing(seoul_data)

```

• On the training set, create a 10 fold CV split

# Fitting MLR Models

First, let’s create some recipes. For the 1st recipe:

• Let’s ignore the date variable for modeling (so we’ll need to remove that or give it a different ID) but use it to create a weekday/weekend (factor) variable. (See step 2 of the shinymodels tutorial! You can use step_date() then step_mutate() with a factor(if_else(...)) to create the variable. I then had to remove the intermediate variable created.)

• Let’s standardize the numeric variables since their scales are pretty different.

• Let’s create dummy variables for the seasons, holiday, and our new day type variable

For the 2nd recipe:

• Do the same steps as above.

• Add in interactions between seasons and holiday, seasons and temp, temp and rainfall. For the seasons interactions, you can use starts_with() to create the proper interactions.

For the 3rd recipe:

• Do the same as the 2nd recipe.

• Add in quadratic terms for each numeric predictor

Now set up our linear model fit to use the “lm” engine.

Fit the models using 10 fold CV via fit_resamples() and consider the training set CV error to choose a best model.

Using your ‘best’ model, fit the model to the entire training data set (use the last_fit() function).

• Compute the RMSE metric on the test set.

• Obtain the final model (fit on the entire training set) coefficient table using extract_fit_parsnip() and tidy().
